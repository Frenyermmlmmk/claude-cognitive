# claude-cognitive v1.2 Intelligence Enhancement

> **Vision**: Transform from static keyword system to adaptive, learning context router with autonomous codebase understanding

**Current State (v1.1):**
- âœ… Keyword-based activation (manual configuration)
- âœ… Decay and co-activation (fixed parameters)
- âœ… History logging (passive observation)
- âœ… Pool coordination (multi-instance awareness)

**Target State (v1.2):**
- ðŸŽ¯ Auto-learning from usage patterns
- ðŸŽ¯ Autonomous codebase exploration
- ðŸŽ¯ Self-generating context documentation
- ðŸŽ¯ Adaptive thresholds and budgeting
- ðŸŽ¯ Semantic understanding
- ðŸŽ¯ Predictive pre-loading
- ðŸŽ¯ **Ralph Loop pattern** - Iterative improvement with feedback â­

**Philosophy (Ralph Loop):**
> "Iteration beats perfection. Let the system try, fail, learn, and retry with objective feedback."

---

## Ralph Loop Integration

**Inspired by**: Geoffrey Huntley's Ralph Wiggum technique for continuous AI agent loops

**Core Pattern**: Instead of one-shot configuration, embrace **iterative refinement with feedback loops**:

```
Discover â†’ Test â†’ Measure â†’ Learn â†’ Refine â†’ Discover (repeat)
```

**Applied to claude-cognitive:**
1. **Foraging Agent** - Discovers files â†’ measures usefulness â†’ adjusts strategy â†’ discovers again
2. **Keyword Tuning** - Tunes weights â†’ measures impact â†’ detects convergence â†’ stops when stable
3. **Semantic Matching** - Learns relevance â†’ tracks accuracy â†’ adapts thresholds
4. **Predictive Loading** - Predicts sequences â†’ validates accuracy â†’ refines predictions

**Ralph Loop Principles:**
- âœ… **Objective feedback** - Usage tracking provides measurable outcomes
- âœ… **Convergence detection** - Know when to stop iterating
- âœ… **Circuit breakers** - Safeguards prevent runaway loops
- âœ… **Progress transparency** - `learning_progress.txt` shows what system learns

**See**: `RALPH_LOOP_INSIGHTS.md` for detailed analysis and implementation patterns

---

## Core Enhancement Pillars

### 1. **Self-Maintaining Documentation System** â­ NEW CONCEPT

**Concept**: Two cooperating background agents that create and maintain `.claude/*.md` context files automatically

**Components:**
1. **Foraging Agent** - Discovers undocumented high-traffic files, generates initial .md
2. **Doc Refiner Agent** - Maintains existing .md files, updates when source changes
3. **Usage Tracker** - Provides intelligence to both agents about what matters

**Unified Behavior:**
```
Usage Tracker (always running)
    â†“
Tracks: Which .md files injected, which source files accessed/edited
    â†“
                    Provides Intelligence
                    /                   \
                   â†“                     â†“
    Foraging Agent                Doc Refiner Agent
    (discovers new)               (maintains existing)
         â†“                              â†“
    Queries: "Which source       Queries: "Which source
     files are accessed          files were edited that
     frequently but have         have existing .md files?"
     no .md file?"
         â†“                              â†“
    Generates new .md            Updates stale .md
         â†“                              â†“
    Usage Tracker validates      Usage Tracker measures
    usefulness (20 turns)        improvement (10 turns)
         â†“                              â†“
    Keep if useful,              Keep if improved,
    delete if noise              rollback if degraded
```

**Key Insight**: Both agents are *driven by usage data* - they know where to look because the tracker shows what's actually being worked on.

**Example Foraging Discovery:**

The agent might discover:
```python
# Scans import statements across project
# Finds: "from core.database import SessionManager" appears in 47 files

# Auto-generates: .claude/modules/session-manager.md
```

```markdown
# Session Manager (Auto-Discovered)

**Location**: `core/database.py:SessionManager`
**Usage**: Imported in 47 files across project
**Role**: Central database session management

## Key Methods
- `get_session()` - Most frequently called (127 references)
- `commit_transaction()` - Often paired with error handlers
- `rollback()` - Error recovery pattern

## Common Patterns
Usually accessed in try/except blocks with rollback on failure.
Frequently co-occurs with: UserModel, TransactionLog

## Auto-Generated Keywords
session, database, transaction, commit, rollback

---
Auto-generated by claude-cognitive foraging agent
Last updated: 2026-01-03 18:45
Usefulness score: Not yet measured
```

**Implementation:**
- Runs during SessionStart hook if >5min since last forage
- Or manual trigger: `python ~/.claude/scripts/forage.py`
- Configurable: `forage_config.json` (which dirs to scan, how deep, thresholds)
- Safe: Never deletes user-written .md files (only `Auto-Discovered` tagged ones)

**Value Proposition:**
- **Zero-config setup** - Works with ANY codebase immediately
- **Self-improving** - Discovers what's actually important through usage
- **Low maintenance** - Auto-updates as codebase evolves
- **Works with existing router** - Just generates .md files

---

### 2. **Usage-Based Learning**

**Track what Claude actually uses, not just what we inject**

**Current Problem:**
```
HOT files injected: pipeline.md, orin.md, asus.md
Claude reads: pipeline.md
Claude edits: (nothing)

Result: Wasted 2/3 of context budget on unused files
```

**Solution: Usage Tracking**
```python
class UsageTracker:
    """Track which injected files Claude actually accessed"""

    def log_turn(self, turn_data):
        """Called after each turn completes"""
        injected = turn_data['hot_files'] + turn_data['warm_files']
        accessed = self._parse_tool_calls(turn_data['tool_calls'])

        # Files injected but never accessed = noise
        wasted = set(injected) - set(accessed)

        # Calculate usefulness per file
        for file in injected:
            if file in accessed:
                self.usefulness[file] += 1  # Used, good!
            else:
                self.usefulness[file] -= 0.5  # Injected but ignored, bad
```

**Adaptive Keyword Tuning:**
```python
# After 50 turns, analyze:
# - "orin" keyword activated orin.md 23 times
# - Claude accessed orin.md 22 of those times
# - Usefulness: 95% â†’ keep keyword, high confidence

# - "pipeline" keyword activated pipeline.md 31 times
# - Claude accessed pipeline.md 8 of those times
# - Usefulness: 26% â†’ lower keyword weight or remove co-activation

# Auto-tune keyword weights based on actual utility
```

**Files:**
- `scripts/usage-tracker.py` (new)
- `scripts/context-router-v2.py` (modified to integrate usage data)
- `.claude/usage_stats.json` (persisted learning data)

---

### 3. **Semantic Keyword Matching**

**Current Problem:**
- User says "authentication" â†’ nothing activates
- `auth-system.md` exists but keyword is "auth" or "session"
- Missed opportunity, Claude explores blindly

**Solution: Fuzzy Semantic Matching**

**Approach A: Embeddings (High Quality)**
```python
# One-time setup: Embed all .claude/*.md files
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')  # 80MB, fast

# Embed file titles + first 200 chars
file_embeddings = {
    'auth-system.md': model.encode("Authentication system session management..."),
    'orin.md': model.encode("Orin sensory cortex layer 0 perception...")
}

# Runtime: Embed user query
query_emb = model.encode("How does authentication work?")

# Find similar files via cosine similarity
similarities = {
    file: cosine_similarity(query_emb, emb)
    for file, emb in file_embeddings.items()
}

# Activate files with similarity > 0.5
# "authentication" query â†’ activates auth-system.md (0.73 similarity)
```

**Approach B: TF-IDF (Lightweight)**
```python
# Simpler, no dependencies
from sklearn.feature_extraction.text import TfidfVectorizer

# Build vocabulary from .claude/*.md content
corpus = [file.read_text() for file in claude_md_files]
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(corpus)

# Match user query
query_vec = vectorizer.transform([user_query])
similarities = cosine_similarity(query_vec, tfidf_matrix)
```

**Hybrid Strategy:**
```python
# Combine keyword matching (fast, explicit) + semantic (smart, fuzzy)
score = 0.6 * keyword_score + 0.4 * semantic_score

# Benefits of both:
# - Keywords: Fast, deterministic, user-controlled
# - Semantic: Handles synonyms, conceptual matches, zero-config
```

**Files:**
- `scripts/semantic-matcher.py` (new)
- `scripts/context-router-v2.py` (integrate semantic scores)
- `.claude/embeddings_cache.pkl` (cached embeddings, regen on .md changes)

---

### 4. **Predictive Pre-Loading**

**Current Problem:**
- User: "Let's work on Orin integration"
- Turn 1: Nothing loaded, Claude explores blindly
- Turn 2: orin.md finally HOT, now Claude has context
- **Wasted Turn 1**

**Solution: Sequence Learning**

**Pattern Recognition:**
```python
# Track sequences: What happens after X?
sequences = {
    'orin.md': {
        'next_within_3_turns': {
            'pipe-to-orin.md': 0.73,  # 73% of time, this follows
            'pipeline.md': 0.45,
            'legion.md': 0.31
        }
    },
    'auth-system.md': {
        'next_within_3_turns': {
            'session-handler.md': 0.89,  # Almost always together
            'database.md': 0.67
        }
    }
}

# When orin.md goes HOT, pre-warm pipe-to-orin.md
# Don't wait for user to mention it
```

**Temporal Patterns:**
```python
# Day-of-week patterns
patterns = {
    'monday_morning': ['deployment.md', 'production-checklist.md'],
    'friday_afternoon': ['release-notes.md', 'changelog.md']
}

# After long break (>24hrs), pre-load recent work
recent_work = history.get_files_from_last_session()
```

**Implementation:**
```python
class PredictivePreloader:
    def predict_next_files(self, current_hot, context):
        """Predict which files will be needed next"""

        # Strategy 1: Sequence learning
        likely_next = self.sequences.get(current_hot, {})

        # Strategy 2: Time-of-day patterns
        time_pattern = self.temporal_patterns.get(context.day_time)

        # Strategy 3: Recent history
        recent = self.get_recent_files(hours=24)

        # Combine predictions
        return self.rank_predictions(likely_next, time_pattern, recent)

    def pre_warm(self, predicted_files):
        """Boost scores for predicted files"""
        for file in predicted_files:
            # Don't fully activate (no keyword match yet)
            # But boost from COLD to low-WARM preemptively
            if self.scores[file] < 0.3:
                self.scores[file] = 0.35  # Pre-warm
```

**Files:**
- `scripts/predictor.py` (new)
- `scripts/context-router-v2.py` (integrate predictions)
- `.claude/sequence_patterns.json` (learned sequences)

---

### 5. **Dynamic Context Budgeting**

**Current Problem:**
- Fixed thresholds: HOT=0.8, WARM=0.25
- Sometimes context nearly empty (5K chars) - could load more
- Sometimes context nearly full (24K chars) - need to be more selective
- **Wastes available budget or overflows**

**Solution: Adaptive Thresholds**

**Budget-Aware Scoring:**
```python
def calculate_dynamic_thresholds(current_usage, budget=25000):
    """Adjust thresholds based on current budget usage"""

    usage_ratio = current_usage / budget

    if usage_ratio < 0.2:  # Nearly empty (<5K chars)
        # Be generous, include more context
        return {
            'hot_threshold': 0.6,   # Lower bar (was 0.8)
            'warm_threshold': 0.15, # More WARM files (was 0.25)
            'decay_rate': 0.90      # Slower decay (was 0.85)
        }

    elif usage_ratio > 0.85:  # Nearly full (>21K chars)
        # Be selective, only critical context
        return {
            'hot_threshold': 0.9,   # Raise bar
            'warm_threshold': 0.4,  # Fewer WARM files
            'decay_rate': 0.80      # Faster decay
        }

    else:  # Normal usage (5K-21K)
        # Standard thresholds
        return {
            'hot_threshold': 0.8,
            'warm_threshold': 0.25,
            'decay_rate': 0.85
        }
```

**Diversity vs Specificity:**
```python
# When budget allows: maximize diversity
# (breadth of context, explore related areas)

# When budget tight: maximize specificity
# (depth on current focus, cut tangential content)

if budget_available > 10000:
    # Include related files even with lower scores
    include_related_files(min_score=0.3)
else:
    # Only most critical files
    include_only_critical(min_score=0.7)
```

**Files:**
- `scripts/context-router-v2.py` (modify threshold calculation)
- Add budget-awareness to scoring logic

---

### 6. **Attention Explanations**

**Current Problem:**
- Black box: "Why did orin.md activate? Why didn't asus.md?"
- Users can't debug or understand behavior

**Solution: Transparent Explanations**

**Enhanced Injection Message:**
```
â•”â•â• ATTENTION STATE [Turn 47] â•â•â•—
â•‘ ðŸ”¥ Hot: 2 â”‚ ðŸŒ¡ï¸ Warm: 5 â”‚ â„ï¸ Cold: 9 â•‘
â•‘ Total chars: 18,420 / 25,000 (74%) â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â” [ðŸ”¥ HOT] systems/orin.md (score: 1.0) â”â”â”
   âœ“ Activated by keywords: "orin", "layer 0"
   âœ“ Co-activated: integrations/pipe-to-orin.md (+0.35)
   âœ“ Previously: WARM (0.67) â†’ promoted to HOT
   âœ“ Used in last turn: Yes (Read tool, line 234)

â”â”â” [ðŸ”¥ HOT] modules/pipeline.md (score: 0.85) â”â”â”
   âœ“ Activated by keywords: "pipeline", "process_message"
   âœ“ Sequence prediction: Often follows orin.md (73% probability)
   âœ“ Previously: HOT (1.0) â†’ decayed slightly
   âœ“ Used in last turn: Yes (Edit tool, 3 changes)

â”â”â” [ðŸŒ¡ï¸ WARM] systems/asus.md (score: 0.45) â”â”â”
   ! No keyword match this turn
   ! Decayed from WARM (0.53) -15%
   ! Not accessed in last 3 turns
   ! Predicted to go COLD next turn unless mentioned

â”â”â” [â„ï¸ COLD] systems/pi5.md (score: 0.18) â”â”â”
   âœ— Below WARM threshold (0.25)
   âœ— No keywords matched
   âœ— Last accessed: 12 turns ago
   â„¹ To reactivate, mention: "pi5", "hmcp", "embodiment"
```

**Debug Mode:**
```bash
# Extra verbose output
export CLAUDE_COGNITIVE_DEBUG=1

# Shows:
# - All keyword matches attempted
# - Semantic similarity scores
# - Why files were excluded
# - Budget calculations
# - Prediction details
```

**Files:**
- `scripts/context-router-v2.py` (enhanced output formatting)
- Add explanation generation logic

---

### 7. **Keyword Suggestions**

**Current Problem:**
- Users don't know what keywords to add
- Default MirrorBot keywords don't match their project
- Trial and error to find good keywords

**Solution: Auto-Suggest Keywords**

**Analysis Script:**
```python
class KeywordSuggester:
    """Analyze codebase and suggest keywords"""

    def analyze_project(self, claude_dir=".claude"):
        """Scan .claude/*.md and actual code"""

        # Extract terms from .claude docs
        doc_terms = self.extract_important_terms(
            glob(f"{claude_dir}/**/*.md")
        )

        # Extract terms from actual code
        code_terms = self.extract_from_code(
            patterns=["**/*.py", "**/*.js", "**/*.ts"]
        )

        # Find frequently mentioned terms NOT in current keywords
        current_keywords = self.get_current_keywords()

        suggestions = []
        for term, count in doc_terms.most_common(50):
            if term not in current_keywords and count > 10:
                suggestions.append({
                    'term': term,
                    'frequency': count,
                    'confidence': 'high' if count > 30 else 'medium'
                })

        return suggestions

    def extract_important_terms(self, md_files):
        """Find important terms in .md files"""
        # Use TF-IDF to find distinctive terms
        # Filter out common words (the, is, are, etc.)
        # Return ranked terms
        pass
```

**User Experience:**
```bash
$ python ~/.claude/scripts/suggest-keywords.py

Analyzing your project...

Found 23 frequently mentioned terms not in your keyword list:

HIGH CONFIDENCE (mentioned 30+ times):
  - "authentication" (47 mentions) - Add to activate auth-system.md
  - "database" (52 mentions) - Add to activate database-schema.md
  - "session" (38 mentions) - Add to activate session-handler.md

MEDIUM CONFIDENCE (mentioned 10-29 times):
  - "websocket" (23 mentions) - Add to activate realtime-sync.md
  - "cache" (19 mentions) - Add to activate caching-layer.md

Add these to your keywords? [y/N]
```

**Auto-Update Keywords:**
```python
# Optional: Automatically add high-confidence keywords
if suggestion.confidence == 'high' and suggestion.frequency > 50:
    self.keywords[suggestion.term] = [f"{suggestion.context}.md"]
    logger.info(f"Auto-added keyword: {suggestion.term}")
```

**Files:**
- `scripts/suggest-keywords.py` (new)
- Interactive CLI tool for keyword tuning

---

### 8. **Multi-Modal Context Injection**

**Current Problem:**
- Only injects `.claude/*.md` files (static architecture docs)
- Claude gets high-level context but not implementation details
- "What does `process_message()` actually do?" â†’ needs to Read file

**Solution: Inject Code Snippets + Metadata**

**Enhanced HOT File Injection:**
```markdown
â”â”â” [ðŸ”¥ HOT] systems/orin.md â”â”â”
[... full .md content ...]

â”â”â” Related Code Snippets â”â”â”

orin_client.py:45-67 (OrinClient.analyze method)
```python
async def analyze(self, user_id: str, message: str) -> Dict:
    """Send message to Orin for Layer 0 analysis"""
    try:
        async with aiohttp.ClientSession() as session:
            response = await session.post(
                f"{self.base_url}/analyze",
                json={"user_id": user_id, "message": message},
                timeout=aiohttp.ClientTimeout(total=5.0)
            )
            return await response.json()
    except asyncio.TimeoutError:
        logger.error("Orin timeout")
        raise OrinUnavailableError()
```

Recent commits touching Orin:
  - c8d777c (2 days ago): "Fix Orin timeout handling"
  - a1b2c3d (1 week ago): "Add Orin health check endpoint"

Recent errors mentioning Orin:
  - [2026-01-03 14:32] OrinUnavailableError: Connection refused
  - [2026-01-03 09:15] Timeout waiting for Orin response

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**Implementation:**
```python
def enhance_hot_file(self, md_file):
    """Add code snippets, commits, errors to .md context"""

    # Original .md content
    content = md_file.read_text()

    # Find related code files
    # (extract from .md mentions, or use file naming)
    related_code = self.find_related_code(md_file)

    # Add key function signatures
    snippets = self.extract_key_functions(related_code, max_lines=50)

    # Add recent git commits
    commits = self.get_recent_commits(related_code, max_commits=3)

    # Add recent errors from logs
    errors = self.get_recent_errors(keywords=self.extract_keywords(md_file))

    # Combine
    enhanced = f"{content}\n\n{snippets}\n\n{commits}\n\n{errors}"

    return enhanced
```

**Budget-Aware:**
- Only add snippets for HOT files (not WARM)
- Limit snippet length based on available budget
- Prioritize most-recently-changed code

**Files:**
- `scripts/context-router-v2.py` (add code snippet injection)
- `scripts/snippet-extractor.py` (new, extract code snippets)

---

### 9. **Pool Collision Detection**

**Current Problem:**
- Instance A working on orin.md
- Instance B also starts working on orin.md
- Neither knows, potential conflicts

**Solution: Collision Warnings**

**Enhanced Pool Protocol:**
```python
# When file goes HOT, claim it in pool
pool.write({
    'instance': 'A',
    'action': 'claimed',
    'topic': 'Working on Orin integration',
    'affects': ['systems/orin.md', 'integrations/pipe-to-orin.md'],
    'duration_estimate': '2 hours',
    'timestamp': '2026-01-03T18:30:00Z'
})

# When Instance B tries to activate same file:
collision = pool.check_collisions(['systems/orin.md'])

if collision:
    warning = f"""
    âš ï¸ COLLISION WARNING

    Instance {collision.instance} is actively working on:
    - systems/orin.md

    Started: {collision.duration_ago} ago
    Status: {collision.status}

    Recommendation: Coordinate before making changes, or work on different files.
    """
    # Show warning in attention state
```

**Smart Collision Detection:**
```python
# Not all collisions are problems
# Same file, different sections = OK
# Same file, read-only = OK
# Same file, both editing = WARN

if collision.instance_action == 'reading' and our_action == 'reading':
    # Both reading, no problem
    pass
elif collision.affects_overlap(our_files) > 0.5:
    # >50% overlap, warn
    show_warning()
```

**Files:**
- `scripts/pool-loader.py` (add collision detection)
- `scripts/pool-auto-update.py` (write claims)
- `.claude/pool/claims.jsonl` (track active claims)

---

### 10. **History-Based Statistics & Tuning**

**Current State:**
- History logs exist (v1.1)
- Not used for intelligence yet

**Enhancement: Learn from History**

**Analysis:**
```python
class HistoryAnalyzer:
    """Analyze attention history to tune behavior"""

    def analyze_file_importance(self, file, days=7):
        """How important is this file recently?"""

        recent_turns = self.history.get_turns(days=days)

        # Count HOT appearances
        hot_count = sum(1 for turn in recent_turns if file in turn['hot'])

        # Count actual accesses
        access_count = sum(1 for turn in recent_turns
                          if file in turn['tools_accessed'])

        # Calculate importance score
        importance = (hot_count * 0.5) + (access_count * 1.0)

        return {
            'file': file,
            'hot_count': hot_count,
            'access_count': access_count,
            'importance': importance,
            'recommendation': self.get_recommendation(importance)
        }

    def get_recommendation(self, importance):
        """What should we do with this file?"""
        if importance > 20:
            return "Core file - boost keyword weights"
        elif importance > 10:
            return "Important file - keep current settings"
        elif importance > 5:
            return "Moderate file - consider lowering thresholds"
        else:
            return "Rarely used - consider removing from .claude/"
```

**Auto-Tuning:**
```python
# Every 50 turns, analyze and tune
if turn_count % 50 == 0:
    analyzer = HistoryAnalyzer()

    for file in all_files:
        stats = analyzer.analyze_file_importance(file)

        if stats['importance'] > 20:
            # This file is core, boost it
            self.boost_keyword_weight(file, multiplier=1.2)

        elif stats['importance'] < 2:
            # This file is never used, consider removing
            logger.info(f"Consider removing {file} - rarely accessed")
```

**Files:**
- `scripts/history-analyzer.py` (new)
- `scripts/context-router-v2.py` (integrate history-based tuning)

---

## Implementation Phases

### Phase 1: Foundation (Week 1-2)
**Goal**: Tracking and visibility

- [ ] **Usage Tracking** (#2) - Know what Claude actually uses
- [ ] **Attention Explanations** (#6) - Make behavior transparent
- [ ] **Keyword Suggestions** (#7) - Help users configure
- [ ] **History Analysis** (#10) - Start learning from past

**Deliverables:**
- `usage-tracker.py`
- Enhanced attention state output
- `suggest-keywords.py` CLI tool
- `history-analyzer.py`

**Testing:**
- Run on claude-cognitive itself
- Run on MirrorBot codebase
- Collect baseline metrics

---

### Phase 2: Intelligence (Week 3-4)
**Goal**: Learning and adaptation

- [ ] **Semantic Matching** (#3) - Understand conceptual queries
- [ ] **Dynamic Budgeting** (#5) - Adapt thresholds
- [ ] **History-Based Tuning** (#10 extended) - Auto-tune from data

**Deliverables:**
- `semantic-matcher.py`
- Adaptive threshold calculation
- Auto-tuning based on 50-turn windows

**Testing:**
- Compare keyword-only vs keyword+semantic
- Measure budget utilization improvement
- Validate auto-tuning doesn't degrade performance

---

### Phase 3: Prediction (Week 5-6)
**Goal**: Proactive context loading

- [ ] **Predictive Pre-Loading** (#4) - Learn sequences
- [ ] **Pool Collision Detection** (#9) - Multi-instance safety

**Deliverables:**
- `predictor.py` with sequence learning
- Enhanced pool protocol with claims
- Collision warnings in attention state

**Testing:**
- Measure turn-1 context quality improvement
- Test multi-instance collision scenarios
- Validate predictions are useful not noisy

---

### Phase 4: Self-Maintaining Documentation (Week 7-9) â­ **BIG ONE** (Ralph Loop Pattern)
**Goal**: Autonomous agents that create and maintain documentation with zero manual effort

#### Phase 4A: Foraging Agent (Week 7)
- [ ] **Usage-driven discovery** - Query tracker for undocumented high-traffic files
- [ ] **Auto-generate .md files** - Create modules/discovered-*.md with Ralph Loop
- [ ] **Validation period** - Wait 20 turns for usefulness measurement
- [ ] **Promotion/cleanup** - Keep useful docs, delete noise

#### Phase 4B: Doc Refiner Agent (Week 8)
- [ ] **Staleness detection** - Query tracker for recently edited source files
- [ ] **Refinement proposals** - Analyze code changes, propose doc updates
- [ ] **A/B testing refinements** - Apply â†’ measure â†’ keep or rollback
- [ ] **Meta-learning** - Learn which refinement strategies work best

#### Phase 4C: Unified Daemon (Week 9)
- [ ] **Background coordination** - Both agents running in same process
- [ ] **Shared query API** - UsageTrackerQuery interface
- [ ] **Convergence detection** - Know when system is stable
- [ ] **Multi-Modal Injection** (#8) - Code snippets + metadata
- [ ] **Circuit Breakers** - Safeguards for autonomous processes
- [ ] **Progress Logging** - `learning_progress.txt` transparency

**Deliverables:**
- `forage.py` - **Ralph Loop foraging agent** (discovers undocumented files)
- `doc-refiner.py` - **Ralph Loop maintenance agent** (updates stale docs)
- `usage_tracker_query.py` - **Shared intelligence API** for both agents
- Auto-generated `.claude/modules/discovered-*.md` files
- Refined `.claude/modules/*.md` files (automatically updated)
- `learning_progress.txt` - Transparent learning log (both agents)
- Code snippet extraction and injection
- Unified daemon with circuit breakers
- Convergence detector (stops when system stable)

**Ralph Loop Implementation:**
```python
# Foraging Agent (forage.py):
while not converged():
    undocumented = query.get_undocumented_sources(min_traffic=5)  # Usage-driven
    generate_md_files(undocumented)                                # Action
    wait_for_usage_data(20)                                        # Feedback delay
    measure_usefulness()                                           # Objective feedback
    promote_or_delete()                                            # Learning

# Doc Refiner Agent (doc-refiner.py):
while not converged():
    stale_docs = query.get_stale_docs()                           # Usage-driven
    proposals = generate_refinements(stale_docs)                   # Action
    apply_proposals()                                              # Test
    wait_for_usage_data(10)                                        # Feedback delay
    measure_improvement()                                          # Objective feedback
    finalize_or_rollback()                                         # Learning

# Both agents check circuit breakers and log to learning_progress.txt
```

**Testing:**

*Foraging Agent:*
- Run on fresh project with zero .claude/ setup
- Measure discovery accuracy (are high-traffic files found?)
- Validate auto-generated .md files match source code
- Test circuit breakers prevent runaway generation

*Doc Refiner Agent:*
- Make source changes, verify .md updates triggered
- Test refinement proposals are accurate
- Verify rollback works when refinement degrades usefulness
- Confirm staleness detection catches edited files

*Unified System:*
- Run both agents together for 100 turns
- Measure convergence time (how many iterations until stable?)
- Verify learning_progress.txt shows clear improvement
- Confirm no conflicts between agents
- Validate end-to-end: discover â†’ refine â†’ maintain cycle

---

## Technical Architecture

### New Components

```
claude-cognitive/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ context-router-v2.py         # [MODIFIED] Add all new intelligence
â”‚   â”œâ”€â”€ usage-tracker.py             # [NEW] Track what Claude uses
â”‚   â”œâ”€â”€ semantic-matcher.py          # [NEW] Fuzzy semantic matching
â”‚   â”œâ”€â”€ predictor.py                 # [NEW] Sequence learning
â”‚   â”œâ”€â”€ forage.py                    # [NEW] â­ Autonomous exploration
â”‚   â”œâ”€â”€ snippet-extractor.py         # [NEW] Extract code snippets
â”‚   â”œâ”€â”€ suggest-keywords.py          # [NEW] Keyword suggestion CLI
â”‚   â”œâ”€â”€ history-analyzer.py          # [NEW] Learn from attention history
â”‚   â””â”€â”€ pool-loader.py               # [MODIFIED] Add collision detection
â”‚
â”œâ”€â”€ .claude/                         # Project-local (example)
â”‚   â”œâ”€â”€ attn_state.json              # [EXISTING] Current scores
â”‚   â”œâ”€â”€ usage_stats.json             # [NEW] Usage learning data
â”‚   â”œâ”€â”€ sequence_patterns.json       # [NEW] Learned sequences
â”‚   â”œâ”€â”€ embeddings_cache.pkl         # [NEW] Semantic embeddings
â”‚   â”œâ”€â”€ forage_config.json           # [NEW] Foraging settings
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ discovered-session-manager.md    # [NEW] Auto-generated
â”‚   â”‚   â”œâ”€â”€ discovered-database-layer.md     # [NEW] Auto-generated
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ pool/
â”‚       â”œâ”€â”€ instance_state.jsonl     # [EXISTING]
â”‚       â””â”€â”€ claims.jsonl             # [NEW] File claims
â”‚
â””â”€â”€ ~/.claude/                       # Global fallback
    â””â”€â”€ attention_history.jsonl      # [EXISTING] v1.1 history
```

### Data Flow

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Keyword Matching (existing)            â”‚ â”€â”€â†’ Base Scores
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Matching (NEW)                â”‚ â”€â”€â†’ +Semantic Scores
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Predictive Pre-Loading (NEW)           â”‚ â”€â”€â†’ +Predicted Files
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usage-Based Adjustment (NEW)           â”‚ â”€â”€â†’ Weight by Usefulness
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dynamic Budgeting (NEW)                â”‚ â”€â”€â†’ Adaptive Thresholds
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-Modal Injection (NEW)            â”‚ â”€â”€â†’ +Code Snippets
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collision Detection (NEW)              â”‚ â”€â”€â†’ Warnings
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Context Injection
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usage Tracking (NEW)                   â”‚ â”€â”€â†’ Learn for Next Time
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Background Tasks

```
SessionStart Hook:
  â”œâ”€ [EXISTING] Load pool state
  â”œâ”€ [EXISTING] Load attention state
  â”œâ”€ [NEW] Check time since last forage
  â”œâ”€ [NEW] If >5min idle, trigger forage agent
  â””â”€ [NEW] Load collision warnings

UserPromptSubmit Hook:
  â”œâ”€ [EXISTING] Compute attention scores
  â”œâ”€ [NEW] Add semantic scores
  â”œâ”€ [NEW] Add predictive pre-loading
  â”œâ”€ [NEW] Apply usage-based weights
  â”œâ”€ [NEW] Dynamic threshold calculation
  â”œâ”€ [NEW] Multi-modal injection
  â””â”€ [EXISTING] Inject context

Stop Hook:
  â”œâ”€ [EXISTING] Extract pool blocks
  â”œâ”€ [NEW] Track which files were accessed (usage)
  â”œâ”€ [NEW] Update sequence patterns
  â”œâ”€ [NEW] Update usage statistics
  â””â”€ [NEW] Release file claims

Idle Time (5min+):
  â””â”€ [NEW] Run foraging agent
      â”œâ”€ Analyze codebase
      â”œâ”€ Generate .claude/modules/discovered-*.md
      â”œâ”€ Check usefulness of previous discoveries
      â””â”€ Prune low-value auto-generated files
```

---

## Migration Path

### For Users

**Upgrade from v1.1 to v1.2:**
```bash
# Pull latest
cd ~/.claude-cognitive
git pull

# Copy new scripts
cp -r scripts/* ~/.claude/scripts/

# No breaking changes - v1.2 is backwards compatible
# All new features are opt-in or auto-enabled safely
```

**First Run Experience:**
```bash
$ claude

# First turn shows enhanced output:
â•”â•â• ATTENTION STATE [Turn 1] â•â•â•—
â•‘ ðŸ”¥ Hot: 0 â”‚ ðŸŒ¡ï¸ Warm: 3 â”‚ â„ï¸ Cold: 12 â•‘
â•‘ ðŸ“Š Running first-time setup...           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” Analyzing your project (first run)...
   âœ“ Found 47 Python files
   âœ“ Discovered 5 core modules
   âœ“ Generated embeddings for semantic matching
   âœ“ Suggested 8 new keywords

ðŸ’¡ Tip: Run `python ~/.claude/scripts/suggest-keywords.py` to review suggestions

[... rest of session proceeds normally ...]
```

**Opt-Out Options:**
```bash
# Disable specific features in ~/.claude/config.json
{
  "semantic_matching": true,      # Fuzzy semantic matching
  "predictive_loading": true,     # Sequence-based prediction
  "auto_foraging": true,          # Autonomous exploration
  "multi_modal_injection": false, # Code snippets (can be noisy)
  "usage_tracking": true          # Learn from behavior
}
```

### For Developers

**Extension Points:**
```python
# Custom foraging strategies
class CustomForager(BaseForager):
    def discover_patterns(self, codebase):
        # Your custom discovery logic
        pass

# Register custom forager
router.register_forager(CustomForager())

# Custom semantic matching
class CustomSemanticMatcher(BaseSemanticMatcher):
    def compute_similarity(self, query, doc):
        # Your custom similarity metric
        pass

# Register custom matcher
router.register_semantic_matcher(CustomSemanticMatcher())
```

---

## Success Metrics

### Quantitative

**Context Quality:**
- âœ… First-turn context completeness: Target >80% (vs ~40% in v1.1)
- âœ… Budget utilization: Target 70-90% (vs 30-100% variance in v1.1)
- âœ… Useful file injection rate: Target >75% (vs ~45% estimated in v1.1)

**Performance:**
- âœ… Time to productivity: Target <1 min (vs ~3-5 min in v1.1)
- âœ… Wasted context: Target <15% (files injected but unused)
- âœ… Foraging overhead: Target <500ms per session start

**Learning:**
- âœ… Keyword auto-tuning: Improve usefulness by >20% after 100 turns
- âœ… Sequence prediction accuracy: Target >60% for next-file prediction
- âœ… Auto-discovered files: Target >50% usefulness rate

### Qualitative

**User Experience:**
- âœ… "Feels smarter" - Claude has right context without explicit setup
- âœ… "Self-improving" - Gets better over time without manual tuning
- âœ… "Transparent" - Users understand why files activate
- âœ… "Low maintenance" - Works well with minimal configuration

**Developer Experience:**
- âœ… Easy to extend (plugin architecture for custom strategies)
- âœ… Easy to debug (clear explanations, logs, metrics)
- âœ… Safe to deploy (backwards compatible, opt-in features)

---

## Open Questions

1. **Foraging Frequency**: How often should auto-foraging run?
   - Too frequent: Wastes compute, generates noise
   - Too rare: Misses important updates
   - **Proposal**: Every 5min idle, OR on-demand, OR nightly cron

2. **Embedding Model**: Which semantic model?
   - `all-MiniLM-L6-v2`: 80MB, fast, good quality
   - `all-mpnet-base-v2`: 420MB, slower, better quality
   - TF-IDF: 0MB (built-in), fastest, lower quality
   - **Proposal**: Start with TF-IDF, offer embedding upgrade

3. **Auto-Generated File Cleanup**: When to delete discovered-*.md?
   - After N turns unused?
   - Never (let users delete)?
   - **Proposal**: Keep for 7 days unused, then archive (don't delete)

4. **Multi-Modal Injection Scope**: How much code to inject?
   - Just function signatures?
   - Full function bodies (can be large)?
   - Top N most-called functions?
   - **Proposal**: Top 3 functions, max 50 lines total per file

5. **Usage Tracking Privacy**: What to log?
   - File accesses only? (safe)
   - Full queries? (powerful but privacy concern)
   - **Proposal**: Only log files + tools, never query content

---

## Next Steps

1. **Review this outline** - Feedback, priorities, concerns?
2. **Prototype Phase 1** - Start with usage tracking + explanations
3. **Test on real projects** - claude-cognitive + MirrorBot
4. **Iterate based on data** - See what actually improves workflow
5. **Community feedback** - Open RFC issue on GitHub?

---

**Questions? Concerns? Ideas to add?**

This is a living document - we'll refine as we build.
